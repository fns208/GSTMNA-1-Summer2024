{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lesson 6 Continued: Assessing Your Models\n",
    "\n",
    "Today:\n",
    "1. Assessing your models\n",
    "    + Accuracy\n",
    "    + Other ways (\"metrics\") to measure goodness of models\n",
    "2. Improving your models\n",
    "   + Incorporating more features\n",
    "   + k-Nearest Neighbor Classifiers\n",
    "   + Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Measuring \"Goodness\" of Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "\n",
    "Consider the cancer dataset. What we have done so far:\n",
    "1. Split the dataset into training and test datasets.\n",
    "2. Using the training dataset:\n",
    "    - Visualize data\n",
    "    - Identify patterns\n",
    "    - Create a model\n",
    "3. Using the test dataset:\n",
    "    - Use the model to make a prediction about the test dataset\n",
    "4. Assess the model\n",
    "    - How good/bad were the predictions made on the test dataset?\n",
    "  \n",
    "      \n",
    "In our linear regression discussion:\n",
    "- Given a proposed line, compute the MSE. Roughly speaking: Smaller MSE = more accurate model.\n",
    "- Among multiple possible lines, choose one with smallest MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Metrics for measuring goodness of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Minimize ``MSE'':\n",
    "$$\\text{MSE} = \\frac{\\text{total (error)}^2} {\\text{Total number of predictions}} $$\n",
    "\n",
    "\n",
    "- Maximize accuracy:\n",
    "$$\\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: The Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancerdata = pd.read_csv('../../../shared/datasets/cancer.csv')\n",
    "cancerdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------\n",
    "# this part simply puts together the pieces we have done previously into one giant code cell\n",
    "\n",
    "# 1. THE DATASET\n",
    "#  split into training and test datasets:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = cancerdata[['Marginal Adhesion', 'Clump Thickness']]\n",
    "Y = cancerdata['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.5, random_state = 11)\n",
    "\n",
    "# 2. THE CLASSIFIER \n",
    "# Encoding a simple classifier\n",
    "#   (this was an example from lesson08)\n",
    "\n",
    "def predict_tumor_class( x , y ):\n",
    "    # x = marginal_adhesion\n",
    "    # y = clump thickness\n",
    "    \n",
    "    if (x < 4 and y < 7):\n",
    "        class_predicted = 0\n",
    "    else:\n",
    "        class_predicted = 1\n",
    "    \n",
    "    return( class_predicted )\n",
    "\n",
    "\n",
    "# 3. PREDICT THE CLASS OF EACH ROW OF THE TEST DATASET, USING A FOR LOOP\n",
    "\n",
    "num_rows_test = len(y_test)\n",
    "print(num_rows_test)\n",
    "\n",
    "\n",
    "# empty array\n",
    "y_predicted = np.empty( num_rows_test )\n",
    "\n",
    "# empty data frame\n",
    "\n",
    "predictions = pd.DataFrame( np.empty( (num_rows_test, 2) ) )\n",
    "predictions.rename( columns = {0:'actual', 1:'predicted'}, inplace = True)\n",
    "\n",
    "for row in np.arange(0, num_rows_test):\n",
    "    predictions.iloc[row, 1] = predict_tumor_class( X.iloc[row, 0], X.iloc[row, 1] )\n",
    "    predictions.iloc[row, 0] = y_test.iloc[row]\n",
    "\n",
    "predictions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# 4. ASSESSMENT\n",
    "# Next, check how good our predictions are, by comparing to the actual class\n",
    "\n",
    "# count how many predictions are incorrect and how many are correct\n",
    "#    add a new column called \"error\"\n",
    "#    if actual class is equal to predicted class, error is 0; else, error is 1\n",
    "\n",
    "predictions['error'] = (predictions['predicted'] - predictions['actual']) ** 2\n",
    "\n",
    "print(np.mean(predictions['error']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Data:**\n",
    "- 20000 images of handwritten characters (A-Z)\n",
    "- 800 of them are images of the letter “A” (label = 1)\n",
    "- the remaining 19200 are images of other characters (label = 0)\n",
    "\n",
    "**Classification Task:** Identify which characters are the letter “A”. \n",
    "\n",
    "**Suppose we have a “Lazy” Classifier:**\n",
    "\n",
    "Whatever the image is, predict “0” (i.e., the image is not of the letter “A”).\n",
    "\n",
    "What is the accuracy of this classifier if we use it to predict the labels of the test data?\n",
    "\n",
    "A. 0 \n",
    "\n",
    "B. $\\dfrac{800 }{20,000}$\n",
    "\n",
    "C. $\\dfrac{800}{19,200}$\n",
    "\n",
    "D. $\\dfrac{19200}{20,000}$\n",
    "\n",
    "E. None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Follow-Up Group Discussion:** Can you come up with an example test dataset for which the accuracy of this classifier’s predictions is very high (e.g., 100%)? Very low?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Even a bad classifier could have a high accuracy if we’re “lucky” with the test dataset that we have.\n",
    "- A good classifier should perform relatively well given **any test dataset**.\n",
    "- Sometimes we cannot rely on just one metric (e.g., accuracy) for evaluating the goodness of a classifier.\n",
    "\n",
    "- **For example:**\n",
    "    - The accuracy of our “lazy classifier” on the given test dataset is high (96%).\n",
    "    - Accuracy captures “percentage of correct predictions out of all predictions that are made”.\n",
    "    - Our “lazy classifier” has a high accuracy because most of the images in the test data happen to be not “A”.\n",
    "    - Our “lazy classifier” fails to correctly identify any image that is an “A”.\n",
    "    - Are there other metrics that capture the above failure of our “lazy classifier”?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Other ways (\"metrics\") to measure goodness of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **True Positive**: the number of data points where \n",
    "    - True label = 1 (+)\n",
    "    - Predicted label = 1 (+)\n",
    "- **False Positive**: the number of data points where\n",
    "    - True label = 0 (-)\n",
    "    - Predicted label = 1 (+)\n",
    "- **True Negative**: the number of data points where \n",
    "    - True label = 0 (-)\n",
    "    - Predicted label = 0 (-)\n",
    "- **False Negative**: the number of data points where\n",
    "    - True label = 1 (+)\n",
    "    - Predicted label = 0 (-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- True = prediction is correct\n",
    "- False = prediction is incorrect\n",
    "- Positive = “predict 1 (+)”\n",
    "- Negative = “predict 0 (-)”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "\n",
    "Predict if a patient has a disease or not.\n",
    "\n",
    "(1 = has disease, 0 = does not have disease)\n",
    "\n",
    "- A true positive: patient has disease, test says they do\n",
    "- A false positive: patient does not have disease, test says they do\n",
    "- A false negative: patient has disease, test says they don’t\n",
    "- A true negative : patient does not have disease, test says they don’t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to calculate the metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/labels.png' width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}} = \\frac{\\text{True Positive + True Negative}}{\\text{TP + TN + FP + FN}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision** = proportion of correct predictions out of all positive predictions\n",
    "\n",
    "$$\\text{Precision} = \\frac{\\text{TP }}{\\text{TP + FP}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**True Positive Rate** = proportion of correct predictions out of all data points whose actual label is 1\n",
    "\n",
    "$$\\text{True Positive Rate} = \\frac{\\text{TP }}{\\text{TP + FN}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**True Negative Rate** = proportion of correct predictions out of all data points whose actual label is 0\n",
    "\n",
    "$$\\text{True Negative Rate} = \\frac{\\text{TN }}{\\text{FP + TN}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: The Cancer Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true positive rate\n",
    "# tp / (tp + fn)\n",
    "tp = 0\n",
    "fn = 0\n",
    "for row in np.arange(0, num_rows_test):\n",
    "    if predictions.iloc[row, 0] == 1:\n",
    "        if predictions.iloc[row, 1] == 1:\n",
    "            tp = tp + 1\n",
    "        else:\n",
    "            fn = fn + 1\n",
    "\n",
    "print(tp/(tp+fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Data:**\n",
    "- 20000 images of handwritten characters (A-Z)\n",
    "- 800 of them are images of the letter “A” (label = 1)\n",
    "- the remaining 19200 are images of other characters (label = 0)\n",
    "\n",
    "**Classification Task:** Identify which characters are the letter “A”. \n",
    "\n",
    "**Suppose we have a “Lazy” Classifier:**\n",
    "\n",
    "Whatever the image is, predict “0” (i.e., the image is not of the letter “A”).\n",
    "\n",
    "What is the **true positive rate** of this classifier if we use it to predict the labels of the test data?\n",
    "\n",
    "A. 0 \n",
    "\n",
    "B. $\\dfrac{800 }{20,000}$\n",
    "\n",
    "C. $\\dfrac{800}{19,200}$\n",
    "\n",
    "D. $\\dfrac{19200}{20,000}$\n",
    "\n",
    "E. None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Improving our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tweak the current model\n",
    "\t- Incorporate more variables\n",
    "\t- Adjust cutoffs  \n",
    "- Consider a different type of model.  \n",
    "\t- The Nearest Neighbor Classifier (a.k.a. the k-nearest neighbor classifier)\n",
    "\t- There are a lot of classification models out there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: The Cancer Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Encoding a simple classifier (version 2)**\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images/lec20-knn-illustration2_wline2.jpg\" width=\"600\"></td>\n",
    "        <td><img src=\"images/dec_tree1b.jpg\" width=\"600\"></td>\n",
    "    </tr>\n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose this classifier based on our training dataset, but we don't know if it fits our test dataset. We may want to adjust the cut-offs. \n",
    "\n",
    "For instance, maybe we want `Marginal Adhesion` to be less than 9 instead of 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Encoding a more complex classifier**\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"images/illustration_ct_uocs.png\" width=\"600\"></td>\n",
    "        <td><img src=\"images/Dec_tree3.jpg\" width=\"600\"></td>\n",
    "    </tr>\n",
    "</table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we want to also consider the `Uniformity of Cell Size` in addition to `Marginal Adhesion` and `Clump Thickness`, where we add another layer to the decision tree above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Example of a New Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/model_tree.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a scatterplot depicting the relationship between 2 variables, where is a datapoint likely to be classified into?\n",
    "\n",
    "<img src='images/cluster1.png' width=500>\n",
    "\n",
    "\n",
    "<sup> image source: https://jakevdp.github.io/PythonDataScienceHandbook/04.02-simple-scatter- plots.html</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The k Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of a 3-Nearest Neighbor classifier**\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src='images/lec21-knn-fig3.png' width=400></td>\n",
    "        <td>\n",
    "            <p><b>Idea:</b></p>\n",
    "<p>Given an unlabeled point, find the 3 labeled points closest to it (most similar to it).</p>\n",
    "<p>Prediction: The “majority-vote winner” of the labels of the 3 nearest points.</p>\n",
    "<p>This is the 3-Nearest Neighbor classifier!</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of a 5-Nearest Neighbor classifier**\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src='images/lec21-knn-fig4.png' width=400></td>\n",
    "        <td>\n",
    "            <p><b>Idea:</b></p>\n",
    "<p>Given an unlabeled point, find the 5 labeled points closest to it (most similar to it).</p>\n",
    "<p>Prediction: The “majority-vote winner” of the labels of the 5 nearest points.</p>\n",
    "<p>This is the 5-Nearest Neighbor classifier!</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The k-Nearest Neighbor Classifier, more generally**\n",
    "\n",
    "- Choose the number of nearest neighbor to be considered (e.g., k = 5).\n",
    "- For each new (unlabeled) point, find its k nearest neighbors.\n",
    "- Find the labels of these k nearest neighbors.\n",
    "- Find which value appears most frequently, among these k labels.\n",
    "- We predict the new point’s label to be this value.\n",
    "- Typically,\n",
    "    - if there are an even amount of labels, we want k to be odd, and\n",
    "    - if there are an odd amount of labels, we want k to be even."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring \"Nearness\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For example:** Suppose we want to know how close the points (1, 1) and (5, 4) are to each other. \n",
    "\n",
    "<img src='images/lec21-dist-fig2.png' width=400>\n",
    "\n",
    "We will measure the distance between the two points. The distance between any two points $(x_1, y_1), (x_2, y_2)$ is\n",
    "\n",
    "$$d = \\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Data:**\n",
    "\n",
    "| Size | Uniformity | Class | Distance to new point |\n",
    "| --- | --- | ---- | ---- |\n",
    "| 6 | 3| 0 | $\\sqrt{(6-4)^2+(3-5)^2}=\\sqrt{18}$\n",
    "| 3 | 2| 0 | $\\sqrt{(3-4)^2+(2-5)^2}=\\sqrt{10}$\n",
    "| 2 | 8| 1 | $\\sqrt{(2-4)^2+(8-5)^2}=\\sqrt{13}$\n",
    "| 10 | 1| 1 | $\\sqrt{(10-4)^2+(1-5)^2}=\\sqrt{52}$\n",
    "| 3| 10| 1 | $\\sqrt{(3-4)^2+(10-5)^2}=\\sqrt{26}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New data point:**\n",
    "\n",
    "| Size | Uniformity | Class | Predicted Class |\n",
    "| --- | --- | ---- | ---- |\n",
    "| 4 | 5|  | ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose k=3: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Similarly if we were to add another variable:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Data:**\n",
    "\n",
    "Var3| Size | Uniformity | Class | Distance to new point |\n",
    "| --- | --- | --- | ---- | ---- |\n",
    "4| 6 | 3| 0 | $\\sqrt{(4-3)^2+(6-4)^2+(3-5)^2}=3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New data point:**\n",
    "\n",
    "Var3 | Size | Uniformity | Class | Predicted Class |\n",
    "| --- | --- | ---- | ---- | --- |\n",
    "|3 | 4 | 5|  | ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kNN using python/scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    model = KNeighborsClassifier(n_neighbors= NUMBER )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_predicted = model.predict(X_test)\n",
    "\n",
    "    accuracy = model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where:\n",
    "- `X_train`: training data (only the feature/attribute columns)\n",
    "- `X_test`: test data (only the feature/attribute columns)\n",
    "- `y_train`: a list containing the labels of the training data\n",
    "- `NUMBER`: the number of nearest neighbors to be considered\n",
    "- output of `model.predict(X_test)`: list of predicted labels of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors= 3 )\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model.predict(X_test)\n",
    "\n",
    "accuracy = model.score(X_test, y_test)\n",
    "\n",
    "print(type(y_predicted))\n",
    "print(y_predicted)\n",
    "print(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn default score is accuracy\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a lot of different models to choose from, including \n",
    "- several different decision tree classifiers (+ any tweaks) and\n",
    "- k-Nearest neighbors, for different values of k.\n",
    "\n",
    "Question: How do we choose which model to use to make actual predictions?\n",
    "\n",
    "Idea: Pick a model that performs the **best** when tested on the **test dataset**.\n",
    "\n",
    "Issue: “Overfitting”\n",
    "- Choosing a model because performs extremely well on on a particular test dataset, but the model is not “generalizable” and does not perform well when given other test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overfitting Issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might end up choosing a model that performs best only on that particular test dataset.\n",
    "\n",
    "**Example: The “Lazy Classifier” Example**\n",
    "- A test dataset that happens to have 96% “0”\n",
    "- A lazy classifier that always predict “0”\n",
    "- The accuracy of the lazy classifier on this dataset would be 96%.\n",
    "    - But this classifier might perform horribly if given other test datasets.\n",
    "- Suppose we have other classifiers whose accuracy on this test dataset are 95%, 91%, 93%, etc. and they also perform similarly if given test datasets.\n",
    "- If we choose the classifier that performs well on this particular test dataset, then we might end up choosing the “lazy” classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection: Avoiding Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initial Idea:\n",
    "    - Divide the dataset into two: training and test\n",
    "    - Train each model using the same training dataset\n",
    "    - Pick a model that performs the **best** when tested on the **same test dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Updated Idea (#1):\n",
    "    - (Shuffle the rows of the dataset)\n",
    "    - Divide the data into M parts\n",
    "    - The first part serves as test dataset; the rest as training. Fit the model using this train-test split.\n",
    "    - The second part serves as test dataset; the rest as training. Fit the model using this train-test split.\n",
    "    - etc.\n",
    "    - Compute the average accuracy\n",
    "    - Pick a model that has the highest test accuracy\n",
    "\n",
    "This method is an example of what’s called “**Cross Validation**”, a model evaluation and selection method that avoids overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Updated Idea (# 2):\n",
    "    - (Shuffle the rows of the dataset)\n",
    "    - Divide the data into M parts\n",
    "        - (for example, if we are selecting among 4 models, divide into 4 parts)\n",
    "    - The first part serves as test dataset for the first model,\n",
    "    - The second part serves as test dataset for the second model, etc.\n",
    "    - Pick a model that performs the best on the test data assigned to it.\n",
    "\n",
    "This method is an example of what’s called “**N-Fold Cross Validation**”, a model evaluation and selection method that avoids overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/K-fold_cross_validation_EN.svg' width=800>\n",
    "\n",
    "<sup>image source: By Gufosowa - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=82298768</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "\n",
    "Suppose we have 600 rows of data in our cancer dataset.\n",
    "\n",
    "We are choosing between four models:\n",
    "\n",
    "1. 1-nearest neighbor,\n",
    "2. 3-nearest neighbor,\n",
    "3. 5-nearest neighbor, and\n",
    "4. 7-nearest neighbor\n",
    "\n",
    "We will split the 600 rows into four equal parts. \n",
    "\n",
    "- Test data for Model 1: Rows 1-150\n",
    "- Test data for Model 2: Rows 151-300\n",
    "- Test data for Model 3: Rows 301-450\n",
    "- Test data for Model 4: Rows 451-600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation using python/scikit-learn + kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    from sklearn.model_selection import cross_validate\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=K)\n",
    "    \n",
    "    cv_results = cross_validate( model, X, Y, cv=NUM )\n",
    "    \n",
    "    cv_results[ ’test_score’ ]\r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where:\n",
    "- `K`: the number of the neighbors to consider in kNN\n",
    "- `X`: a data frame (only the feature/attribute columns)\n",
    "- `Y`: a list containing the data labels\n",
    "- `NUM`: the number of folds/divisions of the dataset to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cross_validate()` is a K-fold cross-validation, where the data set is split into K equal groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: The Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a for loop\n",
    "knnscores_df = pd.DataFrame( np.empty((50, 2)) )\n",
    "knnscores_df.rename(columns = {0:'k', 1:'accuracy'}, inplace = True )\n",
    "row = 0\n",
    "\n",
    "for k in np.arange(1, 51) :\n",
    "    model = KNeighborsClassifier(n_neighbors= k )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    knnscores_df.iloc[row, 0] = k\n",
    "    knnscores_df.iloc[row, 1] = model.score(X_test, y_test)\n",
    "    \n",
    "    row = row + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knnscores_df.sort_values('accuracy', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=knnscores_df, x='k', y='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors= )\n",
    "\n",
    "cv_results = cross_validate( model, X, Y, cv=5 )\n",
    "np.mean(cv_results[ 'test_score' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a for loop\n",
    "knnscores_df2 = pd.DataFrame( np.empty((50, 2)) )\n",
    "knnscores_df2.rename(columns = {0:'k', 1:'accuracy'}, inplace = True )\n",
    "row = 0\n",
    "\n",
    "for k in np.arange(1, 51) :\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    cv_results = cross_validate( model, X, Y, cv=10 )\n",
    "    \n",
    "    knnscores_df2.iloc[row, 0] = k\n",
    "    knnscores_df2.iloc[row, 1] = np.mean(cv_results[ 'test_score' ])\n",
    "    \n",
    "    row = row + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=knnscores_df2, x='k', y='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:py3-11]",
   "language": "python",
   "name": "conda-env-py3-11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
