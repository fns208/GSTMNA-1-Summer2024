{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lesson 4 Continued: Assessing Models\n",
    "\n",
    "Today:\n",
    "1. Assessing Models\n",
    "    + Training and Test data\n",
    "    + Assessing the goodness of a regression model\n",
    "    + Overfitting, Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training and Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far:\n",
    "\n",
    "**Step 1:** Find patterns in data\n",
    "(e.g., there is a linear relationship between x and y)\n",
    "\n",
    "**Step 2:** Build a model that fits the data relatively well  (e.g., fit a line through the plotted data points)\n",
    "\n",
    "**Step 3:** Assess the model\n",
    "- *Qualitatively:* What are the limitations of the model?\n",
    "- *Quantitatively:* If there are **new x values**, how good would the model  be in predicting the y values?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to assess the model:**\n",
    "\n",
    "- We need two sets of data\n",
    "    - First set: Used only to find  patterns and build model\n",
    "    - Second set: Used only to assess  the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='train_test_split.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goals:\n",
    "- Split the dataset into training and test data\n",
    "- Create a model using the training data\n",
    "- Assess the model using the test data\n",
    "    - Compare actual vs. predicted\n",
    "    - How large are the errors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "top50 = pd.read_csv('../../../shared/datasets/top50.csv')\n",
    "\n",
    "top50.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top50.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and Test Data Method 1:** One way to split the data into training and test data is to take the first half as training and the second half and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into test and training\n",
    "#   training_data = row 0 to row 24\n",
    "#   test_data = row 25 to row 49\n",
    "\n",
    "training_data = top50.iloc[ 0:25 , : ]\n",
    "test_data = top50.iloc[ 25:50 , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "sns.regplot(  data = training_data , x = 'LoudnessdB', y = 'Energy'   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train = training_data[['LoudnessdB']]\n",
    "y_train = training_data['Energy']\n",
    "\n",
    "\n",
    "lin_model = LinearRegression().fit( X_train, y_train  )\n",
    "\n",
    "m = lin_model.coef_\n",
    "b = lin_model.intercept_\n",
    "\n",
    "print(m)\n",
    "print(b)\n",
    "print(f\"Equation of best linear curve is y = {round(m[0], 3)}x + {round(b, 3)}\")\n",
    "# predicted energy = m * loudnessdb + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict y values for the test dataset\n",
    "\n",
    "test_data.head()\n",
    "\n",
    "test_data['Energy_predicted'] = test_data['LoudnessdB'] * m + b\n",
    "\n",
    "# compute prediction error\n",
    "test_data['Error'] = test_data['Energy'] - test_data['Energy_predicted']\n",
    "test_data['Error_squared'] = test_data['Error'] ** 2\n",
    "\n",
    "print('MSE (testing) = ' +str(np.mean(test_data['Error_squared'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of computing MSE, can also compute R^2\n",
    "\n",
    "X_test = test_data[['LoudnessdB']]\n",
    "y_test = test_data['Energy']\n",
    "\n",
    "print('R^2 score (testing) = ' + str(lin_model.score( X_test , y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Assessing the goodness of a regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R^2$ score is the square of the correlation coefficient $R$.\n",
    "\n",
    "Recall that MSE is the mean of the squares of the error, where error is measured by distance from the best-fit line.\n",
    "\n",
    "$$R^2 = \\dfrac{Error(mean) - Error(line)}{Error(mean)}$$\n",
    "where \n",
    "- $Error(mean)$ is the sum of the errors between the data points and the mean of the data points and \n",
    "- $Error(line)$ is the sum of the errors between the data points and the line of the data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, $R^2=0.39$. This means that there is 39% less variation around the line than the mean. Meaning, the `LoudnessdB` and `Energy` account for 39% of the variation. This means that 39% of the variation in the data is explained by the `LoudnessdB` and `Energy` relationship, something else must explain the remaining 61%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, $R^2$ is the percentage of variation explained by the relationship between two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly choosing rows for the training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful new functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `np.arange( A, B)`\n",
    "    - Creates a numpy array consisting of numbers starting from A, up to B (not including B)\n",
    "- `np.random.choice( ARRAY, N , replace = False)`\n",
    "    - Randomly selects N elements from ARRAY without replacement\n",
    "- `np.setdiff1d( ARRAY1, ARRAY2)`\n",
    "    - Returns an array containing unique values in ARRAY1 that are not in ARRAY2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and Test Data Method 2:** Another way to split the data is to randomly choose half of the data set as the training and use the remaining half as the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up an array of all of the row indices\n",
    "row_indices = np.arange(0, 50) # list of numbers from 0 to 49\n",
    "\n",
    "# randomly select some row indices for the training data\n",
    "training_row_indices = np.random.choice( row_indices , 25 , replace = False )\n",
    "\n",
    "# the rest of the row indices are for the test data:\n",
    "test_row_indices = np.setdiff1d( row_indices , training_row_indices  )\n",
    "\n",
    "# pick out the rows of the big dataset based on the chosen row indices\n",
    "training_data = top50.iloc[  training_row_indices  , : ]\n",
    "test_data = top50.iloc[ test_row_indices , : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression: What about fitting other curves?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same idea as fitting a line: Find an equation for the curve, such that the MSE  (or other measure of error) is as small as possible.\n",
    "\n",
    "**Example:** \n",
    "\n",
    "Suppose we want to fit a quadratic function $y = ax^2 + bx + c$ through data  points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have three data points $(x_1, y_1), (x_2, y_2), (x_3, y_3)$ that has the pattern of a parabola. Then we want these data points to satisfy the quadratic function above. The goal to is solve for the constants $a, b, c$ such that \n",
    "$$y_1 = ax_1^2 + bx_1 + c$$\n",
    "$$y_2 = ax_2^2 + bx_2 + c$$\n",
    "$$y_3 = ax_3^2 + bx_3 + c$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, this system of equation has no solution, so we will find the \"best-fit\" quadratic function.\n",
    "\n",
    "Idea: Find $a, b, c$ so that the MSE between the curve and the data points are  as small as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if one of the data points is $(2, 3)$, then we plug that into the quadratic equation:\n",
    "$$3 = a(2^2) + b (2) + c \\implies 3=4a+2b+c$$\n",
    "\n",
    "Then $[4, 2, 1]$ will be one of the inputs in X, the training data. ie. one of the rows in our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a polynomial curve using linear regression via python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the best-fit polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the polynomial curve (i.e., one that minimizes MSE):\n",
    "\n",
    "    import seaborn as sns\n",
    "    sns.regplot(data = DATAFRAMENAME, x = ‘COLNAME1’, y = ‘COLNAME2’, order = NUM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "sns.regplot(  data = training_data , x = 'LoudnessdB', y = 'Energy', order = 3  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the equation of the best-fit polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    from sklearn.linear_model import LinearRegression\n",
    "    MODELNAME = LinearRegression().fit( X, Y )\n",
    "\n",
    "Where\n",
    "- X = a **dataframe** with the columns of the **independent variable**\n",
    "- Y = a **list** containing the values of the **dependent variable**\n",
    "\n",
    "And the columns of X includes powers of the variable of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the equation of the cubic polynomial \n",
    "\n",
    "# energy = a * loudness^3 + b * loudness^2 + c * loudness + d\n",
    "# linear regression: find coefficients a, b, c, d that minimizes the MSE\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train = training_data[['LoudnessdB']]\n",
    "y_train = training_data['Energy']\n",
    "\n",
    "\n",
    "#add loudness squared and cubed columns in the X_train data frame\n",
    "X_train['LoudnessdB_squared'] = X_train['LoudnessdB'] ** 2\n",
    "X_train['LoudnessdB_cubed'] = X_train['LoudnessdB'] ** 3\n",
    "X_train.head()\n",
    "\n",
    "lin_model = LinearRegression().fit( X_train, y_train  )\n",
    "\n",
    "m = lin_model.coef_\n",
    "y_intercept = lin_model.intercept_\n",
    "\n",
    "# predicted energy = a * loudness^3 + b * loudness^2 + c * loudness + d\n",
    "print(m)  # the list of a , b, c\n",
    "print(y_intercept) # the y intercept, aka d in the above equation in the comment\n",
    "\n",
    "print(f\"Equation of best cubic curve is y = {round(m[0], 3)}x^3 + {round(m[1],3)}x^2 + {round(m[2],3)}x + {round(y_intercept,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression, with multiple (independent) variables \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train = training_data[['LoudnessdB', 'BeatsPerMinute']]\n",
    "y_train = training_data['Energy']\n",
    "\n",
    "\n",
    "lin_model_multiplevars = LinearRegression().fit( X_train, y_train  )\n",
    "\n",
    "m = lin_model_multiplevars.coef_\n",
    "z_intercept = lin_model_multiplevars.intercept_\n",
    "\n",
    "# energy = a * loudnessdb + b * BeatsPerMinute + c\n",
    "print(m) # the list of a , b\n",
    "print(z_intercept) # the z intercept, aka c in the above equation in the comment\n",
    "\n",
    "print(f\"Equation of best linear curve is z = {round(m[0], 3)}x + {round(m[1],3)}y + {round(z_intercept,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and Test Data Method 3:** Another useful way to split the data, is to use a built-in function in scikit-learn called `train_test_split`.\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = FRACTION, random_state = NUMBER)\n",
    "\n",
    "\n",
    "Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = top50[['LoudnessdB', 'BeatsPerMinute']]\n",
    "Y = top50['Energy']\n",
    "\n",
    "# Be aware of the order of the items returned\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.5, random_state = 11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Overfitting, Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The importance of assessing models\n",
    "(and of using different datasets for building vs. assessing models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overfitting** is the problem that arises when\n",
    "- the model fits the training data really well\n",
    "- but does not make good predictions on new datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overfitting Example:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "    <td><img src='overfit.png' width=500></td>\n",
    "    <td><img src='line.png' width=500></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Underfitting** is the problem that arises when\n",
    "- the model is “too simple” and does not sufficiently capture patterns that arise in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Underfitting Example:**\n",
    "\n",
    "<img src='underfit.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MSE** = Bias + Variance\n",
    "- **Overfitting**: Model is too complex →  Low bias, high variance\n",
    "- **Underfitting**: Model is too simple → High bias, low variance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:py3-11]",
   "language": "python",
   "name": "conda-env-py3-11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
